{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConcretePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfRKgtl_9fFx"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\r\n",
        "\r\n",
        "gdd.download_file_from_google_drive(file_id='1ZKrbsUlrsTgJSlFMz2EGmTINFCQ8PcjO',\r\n",
        "dest_path='content/concrete_crack_data.zip',\r\n",
        "unzip=True)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zonLs0UW-okl"
      },
      "source": [
        "import pandas as pd # Data analysis and manipultion tool\r\n",
        "import numpy as np # Fundamental package for linear algebra and multidimensional arrays\r\n",
        "import tensorflow as tf # Deep Learning Tool\r\n",
        "import os # OS module in Python provides a way of using operating system dependent functionality\r\n",
        "import cv2 # Library for image processing\r\n",
        "from sklearn.model_selection import train_test_split # For splitting the data into train and validation set\r\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cEzr8ICCIHl"
      },
      "source": [
        "data=[]\r\n",
        "img_size=100 # Here we are taking image size as 100, but it's on you. You can take 50 or 40 or 32 and so on\r\n",
        "def create_data():\r\n",
        "    for item in ['Negative','Positive']:\r\n",
        "        path='/content/content/concrete_cracked_images/train/'+item+\"/\"\r\n",
        "\r\n",
        "        for img in os.listdir(path): # os.listdir gets you all the list of name of files located in the given path\r\n",
        "            try:\r\n",
        "                img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE) # converts the image to pixels and gray scales the images\r\n",
        "                new_img_array=cv2.resize(img_array,(img_size,img_size)) # resizing the images\r\n",
        "                if item == 'Negative':\r\n",
        "                    data.append([new_img_array,0])\r\n",
        "                else:\r\n",
        "                   data.append([new_img_array, 1]) # appending the list of image pixels and respective target value (i.e. animal type) in data\r\n",
        "            except Exception as e:\r\n",
        "                    pass # try and except is exception handling case in python, saves you from getting errors\r\n",
        "\r\n",
        "\r\n",
        "create_data()"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5-bwSRcCxsF",
        "outputId": "3a4b1eaa-1c22-4a3f-c47d-c2e30b05af71"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28718"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI2AdRSbDIWG",
        "outputId": "11302199-a2ea-4744-c862-5a362859391e"
      },
      "source": [
        "# image pixels of a image\r\n",
        "data[0]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[164, 167, 169, ..., 158, 153, 156],\n",
              "        [164, 165, 170, ..., 156, 151, 153],\n",
              "        [158, 158, 166, ..., 157, 151, 147],\n",
              "        ...,\n",
              "        [162, 163, 158, ..., 153, 157, 158],\n",
              "        [164, 163, 158, ..., 155, 161, 158],\n",
              "        [161, 164, 166, ..., 155, 156, 152]], dtype=uint8), 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FjPD0PEDNGS"
      },
      "source": [
        "np.random.shuffle(data)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3maYvuinEAhG"
      },
      "source": [
        "x = []\r\n",
        "y = []\r\n",
        "for image in data:\r\n",
        "    x.append(image[0])\r\n",
        "    y.append(image[1])\r\n",
        "\r\n",
        "# converting x & y to numpy array as they are list\r\n",
        "x = np.array(x)\r\n",
        "y = np.array(y)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCFydRUiEDTp",
        "outputId": "69544288-6647-4f5c-d18d-7a3ee0c7987a"
      },
      "source": [
        "np.unique(y, return_counts=True)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([13818, 14900]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR1CuvWcEgg0"
      },
      "source": [
        "# split the data\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(x,y,test_size=0.3, random_state = 42)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA63Q_5_Eo4R",
        "outputId": "75380052-292f-4dcd-fe77-26a671e71157"
      },
      "source": [
        "# Defining the model\r\n",
        "model = tf.keras.Sequential([\r\n",
        "tf.keras.layers.Flatten(input_shape=(100, 100)), # flattening the image\r\n",
        "tf.keras.layers.Dense(100, activation='relu'),\r\n",
        "tf.keras.layers.Dense(100, activation='relu'),\r\n",
        "tf.keras.layers.Dense(100, activation='relu'),\r\n",
        "tf.keras.layers.Dense(50, activation='relu'),\r\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam',\r\n",
        "loss='binary_crossentropy',\r\n",
        "metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=50)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "403/403 [==============================] - 6s 13ms/step - loss: 57.1607 - accuracy: 0.5477\n",
            "Epoch 2/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 5.4181 - accuracy: 0.6319\n",
            "Epoch 3/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.3856 - accuracy: 0.8385\n",
            "Epoch 4/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 1.2770 - accuracy: 0.7666\n",
            "Epoch 5/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.6922 - accuracy: 0.5176\n",
            "Epoch 6/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.6920 - accuracy: 0.5171\n",
            "Epoch 7/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.6922 - accuracy: 0.5213\n",
            "Epoch 8/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.6926 - accuracy: 0.5174\n",
            "Epoch 9/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.6925 - accuracy: 0.5186\n",
            "Epoch 10/10\n",
            "403/403 [==============================] - 5s 13ms/step - loss: 0.6920 - accuracy: 0.5257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f03e9e0e278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQkcrnFsFSWV",
        "outputId": "afea4494-6470-40ea-c0a4-febeec57b5a6"
      },
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "270/270 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.5183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.692409873008728, 0.5183379650115967]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "dx-Nd7GeGQHd",
        "outputId": "23a2fc49-7d32-4b83-8ef9-a6685c28f3c9"
      },
      "source": [
        "test_image_order = pd.read_csv(\"/content/content/concrete_cracked_images/Testing_set_concrete_crack.csv\")\r\n",
        "test_image_order.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename\n",
              "0  Image_1.jpg\n",
              "1  Image_2.jpg\n",
              "2  Image_3.jpg\n",
              "3  Image_4.jpg\n",
              "4  Image_5.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVLMhOoQGoIa"
      },
      "source": [
        "file_paths = [[fname, '/content/content/concrete_cracked_images/test/' + fname] for fname in test_image_order['filename']]"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOU8Od9yGwmu",
        "outputId": "600b9cfd-bf9a-45b8-a542-dc2fecc9c86d"
      },
      "source": [
        "# Confirm if number of images is same as number of labels given\r\n",
        "if len(test_image_order) == len(file_paths):\r\n",
        "  print('Number of image names i.e. ', len(test_image_order), 'matches the number of file paths i.e. ', len(file_paths))\r\n",
        "else:\r\n",
        "  print('Number of image names does not match the number of filepaths')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of image names i.e.  11282 matches the number of file paths i.e.  11282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "36UAcwotG5T6",
        "outputId": "f8f678db-b4d4-4145-8b1f-9f0417e5903d"
      },
      "source": [
        "test_images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\r\n",
        "test_images.head()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>/content/content/concrete_cracked_images/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>/content/content/concrete_cracked_images/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>/content/content/concrete_cracked_images/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>/content/content/concrete_cracked_images/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>/content/content/concrete_cracked_images/test/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename                                          filepaths\n",
              "0  Image_1.jpg  /content/content/concrete_cracked_images/test/...\n",
              "1  Image_2.jpg  /content/content/concrete_cracked_images/test/...\n",
              "2  Image_3.jpg  /content/content/concrete_cracked_images/test/...\n",
              "3  Image_4.jpg  /content/content/concrete_cracked_images/test/...\n",
              "4  Image_5.jpg  /content/content/concrete_cracked_images/test/..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w52bpJ0NHVB-"
      },
      "source": [
        "test_pixel_data = [] # initialize an empty numpy array\r\n",
        "image_size = 100 # image size taken is 100 here. one can take other size too\r\n",
        "for i in range(len(test_images)):\r\n",
        "    img_array = cv2.imread(test_images['filepaths'][i], cv2.IMREAD_GRAYSCALE) # converting the image to gray scale\r\n",
        "    new_img_array = cv2.resize(img_array, (image_size, image_size)) # resizing the image array\r\n",
        "    test_pixel_data.append(new_img_array)\r\n",
        "test_pixel_data = np.array(test_pixel_data)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykjdDwnvHl9V"
      },
      "source": [
        "test_pixel_data = np.array(test_pixel_data)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEMcHdpGHqJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586be2f6-9e7e-4734-c6fe-41fb8bb4fded"
      },
      "source": [
        "pred = model.predict(test_pixel_data)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f03e05b2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qXAoAJQHtkv",
        "outputId": "011d036f-f080-4162-d838-950eba8fa466"
      },
      "source": [
        "# The predicted values are the probabilities value\r\n",
        "pred[0]"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.51583976], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFckHp49Hwgh"
      },
      "source": [
        "prediction = []\r\n",
        "for value in pred:\r\n",
        "    if value < 0.5:\r\n",
        "        prediction.append(\"Negative\")\r\n",
        "    else:\r\n",
        "        prediction.append(\"Positive\")"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x98w-2IxUFjt"
      },
      "source": [
        "res = pd.DataFrame({'prediction':prediction})"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlAzROmsVRFE"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJyDKuGTVlMq"
      },
      "source": [
        "res.to_csv(\"ConcretePrediction.csv\", index = False)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoMzNoshVr_y"
      },
      "source": [
        "#files.download('ConcretePrediction.csv')"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "i5m3ZVmOVyMD",
        "outputId": "a6ae2383-f9a5-4faf-e90b-f4738d0504dc"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download('ConcretePrediction.csv')"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_154e4029-fcfa-44c7-b929-3cc0a71419fa\", \"ConcretePrediction.csv\", 101549)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}